# ğŸ—ï¸ Lakehouse â€” Plateforme complÃ¨te de dÃ©tection de fraude, orchestration, analyse et dÃ©ploiement cloud

Ce projet propose une architecture data/ML moderne, modulaire et automatisÃ©e, pour la dÃ©tection de fraude, lâ€™analyse de donnÃ©es, le monitoring, la visualisation et le dÃ©ploiement cloud. Chaque composant, script et configuration est abondamment commentÃ© pour faciliter la comprÃ©hension, la maintenance et lâ€™extension du projet.

---

## ğŸš€ FonctionnalitÃ©s principales
- **API FastAPI Datamarts** (`api/`) : endpoints REST pour lâ€™accÃ¨s et lâ€™interrogation des datamarts (features, statistiques, donnÃ©es agrÃ©gÃ©es issues de Spark/PostgreSQL). Aucun endpoint de dÃ©tection de fraude ici.
- **API sources** (`sources_api/`) : ingestion, split, alimentation PostgreSQL, scripts Python commentÃ©s (api.py, db.py, split.py, entrypoint.sh, requirements.txt).
- **Pipeline Lakehouse** (`lakehouse/`) : orchestration Spark, MLflow, MinIO, scripts pipeline (datamarts, feeder, ml, preprocessing, signals), tous commentÃ©s section par section.
- **Machine Learning API** (`api_ml/api/`) : API FastAPI dÃ©diÃ©e Ã  lâ€™infÃ©rence ML, expose lâ€™endpoint `/predict` pour la dÃ©tection de fraude, Dockerfile et scripts commentÃ©s.
- **Interface utilisateur ML** (`api_ml/ui/`) : application Streamlit pour la prÃ©diction et la visualisation, code et Dockerfile commentÃ©s.
- **Base de donnÃ©es PostgreSQL** (`postgres/`) : Dockerfile et script dâ€™initialisation SQL commentÃ©s.
- **Elasticsearch** (`elasticsearch/`) : Dockerfile commentÃ©.
- **Monitoring Prometheus** (`prometheus/`) : Dockerfile et prometheus.yml commentÃ©s (explication de chaque cible et mÃ©trique).
- **Visualisation Grafana** (`grafana/`) : Dockerfile commentÃ©, provisioning automatisÃ©.
- **DÃ©ploiement automatisÃ©** (`srv/`) : scripts Bash, Terraform, Ansible, gÃ©nÃ©ration dynamique dâ€™inventaire, tous abondamment commentÃ©s.

---

## Services principaux et ports exposÃ©sâ€¯:
| Service         | Port hÃ´te | Description                                      |
|-----------------|-----------|--------------------------------------------------|
| api             | 9999      | API FastAPI pour lâ€™accÃ¨s et lâ€™interrogation des datamarts (accÃ¨s aux donnÃ©es agrÃ©gÃ©es, features, statistiques, etc.). Aucun endpoint de dÃ©tection de fraude ici. |
| api_ml          | 9997      | API de prÃ©diction ML (endpoint /predict pour la dÃ©tection de fraude)         |
| ui_api_ml       | 8501      | Interface utilisateur Streamlit (consommation de lâ€™API ML) |
| sources_api     | 9998      | API dâ€™ingestion et de gestion des donnÃ©es sources|
| lakehouse       | 1000+     | Orchestration Spark, MLflow, MinIO, etc.         |
| postgres        | 5432      | Base de donnÃ©es relationnelle                    |
| grafana         | 3000      | Monitoring et dashboards                         |
| prometheus      | 9090      | Monitoring des mÃ©triques                         |
| elasticsearch   | 9200      | Recherche et logs                                |

**Remarque** : Les ports et services sont dÃ©taillÃ©s dans [`docker-compose.yml`](docker-compose.yml) (voir les commentaires pour chaque service).

---

## ğŸ—ºï¸ Architecture dÃ©taillÃ©e du projet

```
.
â”œâ”€â”€ docker-compose.yml         # Orchestration multi-conteneurs, chaque service/port/dÃ©pendance commentÃ©
â”œâ”€â”€ api/                      # Backend FastAPI Datamarts (accÃ¨s aux features, stats, datamarts, pas de prÃ©diction)
â”‚   â”œâ”€â”€ fastapi_app.py        # Application principale FastAPI, routes, logique mÃ©tier
â”‚   â”œâ”€â”€ database.py           # Connexion PostgreSQL, gestion sessions
â”‚   â”œâ”€â”€ schemas.py            # ModÃ¨les Pydantic, validation
â”‚   â”œâ”€â”€ routers/              # Routes modulaires (features, risques, etc.), chaque fichier commentÃ©
â”‚   â””â”€â”€ ...
â”œâ”€â”€ sources_api/              # API dâ€™ingestion, split, alimentation BDD
â”‚   â”œâ”€â”€ api.py                # FastAPI pour ingestion, routes commentÃ©es
â”‚   â”œâ”€â”€ db.py                 # Chargement CSV â†’ PostgreSQL, logique commentÃ©e
â”‚   â”œâ”€â”€ split.py              # DÃ©coupe de CSV, script commentÃ© ligne Ã  ligne
â”‚   â”œâ”€â”€ entrypoint.sh         # Script dâ€™entrÃ©e, attente BDD, alimentation, commentaires FR
â”‚   â”œâ”€â”€ requirements.txt      # DÃ©pendances, chaque ligne expliquÃ©e
â”‚   â””â”€â”€ ...
â”œâ”€â”€ lakehouse/                # Orchestration, pipeline, MLflow, Spark, MinIO
â”‚   â”œâ”€â”€ orchestrator.py       # Orchestration globale, gestion des jobs, commentaires dÃ©taillÃ©s
â”‚   â”œâ”€â”€ mlflow_minio_artifact_repo.py # IntÃ©gration MLflow/MinIO, explications
â”‚   â”œâ”€â”€ entrypoint.sh         # Script dâ€™entrÃ©e, commentaires sur chaque Ã©tape
â”‚   â”œâ”€â”€ pipeline/             # Scripts pipeline (datamarts, feeder, ml, preprocessing, signals), chaque script commentÃ©
â”‚   â””â”€â”€ ...
â”œâ”€â”€ api_ml/                   # API ML et UI Streamlit
â”‚   â”œâ”€â”€ api/main.py           # API FastAPI ML, endpoint /predict, logique, commentaires
â”‚   â”œâ”€â”€ api/Dockerfile        # Dockerfile commentÃ©
â”‚   â”œâ”€â”€ ui/streamlit_app.py   # Interface Streamlit, logique, UI, commentaires
â”‚   â”œâ”€â”€ ui/Dockerfile         # Dockerfile commentÃ©
â”‚   â””â”€â”€ ...
â”œâ”€â”€ postgres/                 # Base de donnÃ©es PostgreSQL
â”‚   â”œâ”€â”€ Dockerfile            # Dockerfile commentÃ©
â”‚   â”œâ”€â”€ init.sql              # Script dâ€™initialisation SQL, chaque commande expliquÃ©e
â”œâ”€â”€ elasticsearch/            # Dockerfile commentÃ©
â”œâ”€â”€ prometheus/               # Dockerfile, prometheus.yml commentÃ©s (explication de chaque section)
â”œâ”€â”€ grafana/                  # Dockerfile commentÃ©
â”œâ”€â”€ srv/                      # DÃ©ploiement cloud (scripts, Ansible, Terraform)
â”‚   â”œâ”€â”€ deploy_pipeline.sh    # Script Bash, chaque Ã©tape expliquÃ©e
â”‚   â”œâ”€â”€ ansible/              # Playbook, inventaire, templates, scripts Python, tous commentÃ©s
â”‚   â”œâ”€â”€ infra/                # main.tf, variables.tf, chaque ressource/variable expliquÃ©e
â”‚   â””â”€â”€ ...
â”œâ”€â”€ .lfsconfig                # Config LFS, commentaire sur lâ€™usage
â””â”€â”€ README.md                 # Ce fichier, guide complet
```

---

## ğŸ“¦ Images Docker prÃ©-compilÃ©es

Toutes les images Docker nÃ©cessaires au projet sont dÃ©jÃ  compilÃ©es et disponibles dans le registre GitLabâ€¯:

â¡ï¸ https://gitlab.com/SidyLaye/lakehouse-lfs/container_registry/

Vous pouvez utiliser ces images directement dans vos dÃ©ploiements (cloud, CI/CD, etc.) sans avoir Ã  les reconstruire localement.

---

## ğŸ“ DÃ©tail des fichiers commentÃ©s et pÃ©dagogiques

- **docker-compose.yml** : chaque service, port, dÃ©pendance et rÃ©seau expliquÃ©.
- **api/** : routes, schÃ©mas, accÃ¨s BDD, routers, tout commentÃ© pour la comprÃ©hension mÃ©tier et technique.
- **sources_api/** :
  - `api.py`, `db.py`, `split.py`, `entrypoint.sh` : chaque fonction, section, logique mÃ©tier expliquÃ©e en franÃ§ais.
  - `requirements.txt` : chaque dÃ©pendance explicitÃ©e.
- **lakehouse/** :
  - `orchestrator.py`, `mlflow_minio_artifact_repo.py`, `entrypoint.sh` : orchestration, gestion artefacts, scripts dâ€™entrÃ©e, tous commentÃ©s.
  - `pipeline/` : chaque script (datamarts, feeder, ml, preprocessing, signals) commentÃ© pour expliquer la logique mÃ©tier et technique.
- **api_ml/** :
  - `api/main.py`, `ui/streamlit_app.py` : endpoints, logique ML, UI, tout commentÃ©.
  - Dockerfile de chaque sous-module commentÃ©.
- **postgres/** : Dockerfile et init.sql commentÃ©s (explication de chaque commande SQL).
- **elasticsearch/**, **prometheus/**, **grafana/** : Dockerfile et fichiers de configuration commentÃ©s.
- **srv/** :
  - `deploy_pipeline.sh` : script Bash, chaque Ã©tape expliquÃ©e (variables, Terraform, Ansible, etc.).
  - `ansible/` : playbook, inventaire, templates Jinja2, scripts Python, tous commentÃ©s pour le dÃ©ploiement automatisÃ©.
  - `infra/` : `main.tf`, `variables.tf` (Terraform), chaque ressource et variable expliquÃ©e.
- **.lfsconfig** : configuration LFS, commentaire sur lâ€™usage.

---

## âš™ï¸ DÃ©ploiement cloud (AWS EC2, Terraform, Ansible)

### Ã‰tapes dÃ©taillÃ©es
1. **PrÃ©parer les credentials** :
   - Modifier les fichiers sous `srv/_credentials` (clÃ© AWS, clÃ© SSH, etc.).
2. **Adapter les variables** :
   - Modifier les variables dans `srv/deploy_pipeline.sh` et `srv/infra/variables.tf` selon votre environnement (profil AWS, rÃ©gion, type dâ€™instance, etc.).
3. **Lancer le dÃ©ploiement** :
   ```sh
   cd srv
   bash deploy_pipeline.sh
   ```
   - Provisionnement de lâ€™infrastructure (tofu/Terraform)
   - GÃ©nÃ©ration dynamique de lâ€™inventaire Ansible (template Jinja2, script Python commentÃ©)
   - DÃ©ploiement automatisÃ© de tous les services Docker sur les VMs (playbook Ansible commentÃ©)

Chaque Ã©tape, script et configuration est abondamment commentÃ© pour vous guider.

---

## ğŸ”¬ Exemples dâ€™utilisation

### Appel API de prÃ©diction (FastAPI ML)

Lâ€™API de prÃ©diction est exposÃ©e par le service `api_ml` sur le port 9997 (voir docker-compose.yml). Pour y accÃ©der depuis un autre conteneur ou via le rÃ©seau Docker, utilisez lâ€™URL suivanteâ€¯:

```
http://api_ml:9997/predict
```

Pour tester depuis lâ€™hÃ´te (si le port 9997 est exposÃ©), utilisezâ€¯:

```
http://localhost:9997/predict
```

#### Exemple de requÃªte curl (depuis lâ€™hÃ´te)
```sh
curl -X POST "http://localhost:9997/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "amount": 123.45,
       "card_brand": "VISA",
       "card_type": "CREDIT",
       "merchant_state": "NY",
       "use_chip": "True",
       "credit_limit": 5000,
       "per_capita_income": 35000,
       "yearly_income": 42000,
       "total_debt": 1000,
       "credit_score": 700,
       "num_credit_cards": 2
     }'
```

RÃ©ponse attendueâ€¯:
```json
{
  "fraud_probability": 0.15,
  "is_fraud": false,
  "confidence": "Moyenne"
}
```

> **Remarque** : Lâ€™URL de lâ€™API peut diffÃ©rer selon votre environnement (rÃ©seau Docker, cloud, etc.). Dans lâ€™interface Streamlit, lâ€™URL par dÃ©faut est `http://api_ml:9997` (modifiable dans la barre latÃ©rale).

### Utilisation de lâ€™interface Streamlit
- AccÃ©dez Ã  lâ€™URL du service `ui_api_ml` (par dÃ©faut http://localhost:8501 si exposÃ©).
- Renseignez lâ€™URL de lâ€™API ML dans la barre latÃ©rale si besoin.
- Remplissez le formulaire, cliquez sur "PrÃ©dire" pour obtenir le rÃ©sultat, visualisez les mÃ©triques et lâ€™historique.

### Gestion des conteneurs
```sh
docker compose logs -f         # Logs en temps rÃ©el
docker compose exec api bash   # AccÃ¨s shell au conteneur API
docker compose exec ui_api_ml bash # AccÃ¨s shell Ã  lâ€™UI ML
```

---

## ğŸ‘¥ Contributeurs

Merci Ã  tous les contributeurs du projetâ€¯:
- [SidyLaye](https://github.com/SidyLaye)
- [adamowski13](https://github.com/adamowski13)
- [Lolowyn](https://github.com/Lolowyn)

Contributions, issues et suggestions sont les bienvenuesâ€¯!

---

## ğŸ“š Ressources utiles
- Documentation FastAPI : https://fastapi.tiangolo.com/
- Documentation Streamlit : https://docs.streamlit.io/
- Documentation Docker Compose : https://docs.docker.com/compose/
- Documentation Terraform : https://www.terraform.io/docs/
- Documentation Ansible : https://docs.ansible.com/

---

## ğŸ“ Licence
Ce projet est distribuÃ© sous licence MIT.
