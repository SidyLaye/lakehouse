# ğŸ—ï¸ Lakehouse â€” Plateforme complÃ¨te de dÃ©tection de fraude, orchestration, analyse et dÃ©ploiement cloud

Ce projet propose une architecture data/ML moderne, modulaire et automatisÃ©e, pour la dÃ©tection de fraude, lâ€™analyse de donnÃ©es, le monitoring, la visualisation et le dÃ©ploiement cloud. Chaque composant, script et configuration est abondamment commentÃ© pour faciliter la comprÃ©hension, la maintenance et lâ€™extension du projet.

---

## ğŸš€ FonctionnalitÃ©s principales
- **API FastAPI** (`api/`) : endpoints REST pour la dÃ©tection de fraude, documentation Swagger, code commentÃ© (routes, schÃ©mas, accÃ¨s BDD, features).
- **API sources** (`sources_api/`) : ingestion, split, alimentation PostgreSQL, scripts Python commentÃ©s (api.py, db.py, split.py, entrypoint.sh, requirements.txt).
- **Pipeline Lakehouse** (`lakehouse/`) : orchestration Spark, MLflow, MinIO, scripts pipeline (datamarts, feeder, ml, preprocessing, signals), tous commentÃ©s section par section.
- **Machine Learning API** (`api_ml/api/`) : API FastAPI dÃ©diÃ©e Ã  lâ€™infÃ©rence ML, Dockerfile et scripts commentÃ©s.
- **Interface utilisateur ML** (`api_ml/ui/`) : application Streamlit pour la prÃ©diction et la visualisation, code et Dockerfile commentÃ©s.
- **Base de donnÃ©es PostgreSQL** (`postgres/`) : Dockerfile et script dâ€™initialisation SQL commentÃ©s.
- **Elasticsearch** (`elasticsearch/`) : Dockerfile commentÃ©.
- **Monitoring Prometheus** (`prometheus/`) : Dockerfile et prometheus.yml commentÃ©s (explication de chaque cible et mÃ©trique).
- **Visualisation Grafana** (`grafana/`) : Dockerfile commentÃ©, provisioning automatisÃ©.
- **DÃ©ploiement automatisÃ©** (`srv/`) : scripts Bash, Terraform, Ansible, gÃ©nÃ©ration dynamique dâ€™inventaire, tous abondamment commentÃ©s.

---

## ğŸ“¦ DÃ©marrage rapide (local, Docker Compose)

### PrÃ©requis
- Docker et Docker Compose installÃ©s
- Ports suivants disponibles : 5432, 9999, 9998, 1000, 5000, 9870, 8088, 7077, 8000, 9000, 9001, 9200, 9090, 3000, 9997, 8501

### Lancement des services
```bash
docker compose build
# puis
docker compose up -d
```

### ArrÃªt et gestion des services
```bash
docker compose down           # ArrÃªt de tous les services
docker compose logs -f        # Logs en temps rÃ©el
docker compose ps             # Statut des conteneurs
docker compose build --no-cache  # Reconstruction complÃ¨te
```

### AccÃ¨s aux interfaces
- **API principale** : http://localhost:9999/docs (Swagger)
- **API sources** : http://localhost:9998/docs
- **Interface ML (Streamlit)** : http://localhost:8501
- **Grafana** : http://localhost:3000
- **Prometheus** : http://localhost:9090

---

## ğŸ—ºï¸ Architecture dÃ©taillÃ©e du projet

```
.
â”œâ”€â”€ docker-compose.yml         # Orchestration multi-conteneurs, chaque service/port/dÃ©pendance commentÃ©
â”œâ”€â”€ api/                      # Backend FastAPI (routes, schÃ©mas, BDD, features, tout commentÃ©)
â”‚   â”œâ”€â”€ fastapi_app.py        # Application principale FastAPI, routes, logique mÃ©tier
â”‚   â”œâ”€â”€ database.py           # Connexion PostgreSQL, gestion sessions
â”‚   â”œâ”€â”€ schemas.py            # ModÃ¨les Pydantic, validation
â”‚   â”œâ”€â”€ routers/              # Routes modulaires (features, risques, etc.), chaque fichier commentÃ©
â”‚   â””â”€â”€ ...
â”œâ”€â”€ sources_api/              # API dâ€™ingestion, split, alimentation BDD
â”‚   â”œâ”€â”€ api.py                # FastAPI pour ingestion, routes commentÃ©es
â”‚   â”œâ”€â”€ db.py                 # Chargement CSV â†’ PostgreSQL, logique commentÃ©e
â”‚   â”œâ”€â”€ split.py              # DÃ©coupe de CSV, script commentÃ© ligne Ã  ligne
â”‚   â”œâ”€â”€ entrypoint.sh         # Script dâ€™entrÃ©e, attente BDD, alimentation, commentaires FR
â”‚   â”œâ”€â”€ requirements.txt      # DÃ©pendances, chaque ligne expliquÃ©e
â”‚   â””â”€â”€ ...
â”œâ”€â”€ lakehouse/                # Orchestration, pipeline, MLflow, Spark, MinIO
â”‚   â”œâ”€â”€ orchestrator.py       # Orchestration globale, gestion des jobs, commentaires dÃ©taillÃ©s
â”‚   â”œâ”€â”€ mlflow_minio_artifact_repo.py # IntÃ©gration MLflow/MinIO, explications
â”‚   â”œâ”€â”€ entrypoint.sh         # Script dâ€™entrÃ©e, commentaires sur chaque Ã©tape
â”‚   â”œâ”€â”€ pipeline/             # Scripts pipeline (datamarts, feeder, ml, preprocessing, signals), chaque script commentÃ©
â”‚   â””â”€â”€ ...
â”œâ”€â”€ api_ml/                   # API ML et UI Streamlit
â”‚   â”œâ”€â”€ api/main.py           # API FastAPI ML, endpoints, logique, commentaires
â”‚   â”œâ”€â”€ api/Dockerfile        # Dockerfile commentÃ©
â”‚   â”œâ”€â”€ ui/streamlit_app.py   # Interface Streamlit, logique, UI, commentaires
â”‚   â”œâ”€â”€ ui/Dockerfile         # Dockerfile commentÃ©
â”‚   â””â”€â”€ ...
â”œâ”€â”€ postgres/                 # Base de donnÃ©es PostgreSQL
â”‚   â”œâ”€â”€ Dockerfile            # Dockerfile commentÃ©
â”‚   â”œâ”€â”€ init.sql              # Script dâ€™initialisation SQL, chaque commande expliquÃ©e
â”œâ”€â”€ elasticsearch/            # Dockerfile commentÃ©
â”œâ”€â”€ prometheus/               # Dockerfile, prometheus.yml commentÃ©s (explication de chaque section)
â”œâ”€â”€ grafana/                  # Dockerfile commentÃ©
â”œâ”€â”€ srv/                      # DÃ©ploiement cloud (scripts, Ansible, Terraform)
â”‚   â”œâ”€â”€ deploy_pipeline.sh    # Script Bash, chaque Ã©tape expliquÃ©e
â”‚   â”œâ”€â”€ ansible/              # Playbook, inventaire, templates, scripts Python, tous commentÃ©s
â”‚   â”œâ”€â”€ infra/                # main.tf, variables.tf, chaque ressource/variable expliquÃ©e
â”‚   â””â”€â”€ ...
â”œâ”€â”€ .lfsconfig                # Config LFS, commentaire sur lâ€™usage
â””â”€â”€ README.md                 # Ce fichier, guide complet
```

---

## ğŸ“ DÃ©tail des fichiers commentÃ©s et pÃ©dagogiques

- **docker-compose.yml** : chaque service, port, dÃ©pendance et rÃ©seau expliquÃ©.
- **api/** : routes, schÃ©mas, accÃ¨s BDD, routers, tout commentÃ© pour la comprÃ©hension mÃ©tier et technique.
- **sources_api/** :
  - `api.py`, `db.py`, `split.py`, `entrypoint.sh` : chaque fonction, section, logique mÃ©tier expliquÃ©e en franÃ§ais.
  - `requirements.txt` : chaque dÃ©pendance explicitÃ©e.
- **lakehouse/** :
  - `orchestrator.py`, `mlflow_minio_artifact_repo.py`, `entrypoint.sh` : orchestration, gestion artefacts, scripts dâ€™entrÃ©e, tous commentÃ©s.
  - `pipeline/` : chaque script (datamarts, feeder, ml, preprocessing, signals) commentÃ© pour expliquer la logique mÃ©tier et technique.
- **api_ml/** :
  - `api/main.py`, `ui/streamlit_app.py` : endpoints, logique ML, UI, tout commentÃ©.
  - Dockerfile de chaque sous-module commentÃ©.
- **postgres/** : Dockerfile et init.sql commentÃ©s (explication de chaque commande SQL).
- **elasticsearch/**, **prometheus/**, **grafana/** : Dockerfile et fichiers de configuration commentÃ©s.
- **srv/** :
  - `deploy_pipeline.sh` : script Bash, chaque Ã©tape expliquÃ©e (variables, Terraform, Ansible, etc.).
  - `ansible/` : playbook, inventaire, templates Jinja2, scripts Python, tous commentÃ©s pour le dÃ©ploiement automatisÃ©.
  - `infra/` : `main.tf`, `variables.tf` (Terraform), chaque ressource et variable expliquÃ©e.
- **.lfsconfig** : configuration LFS, commentaire sur lâ€™usage.

---

## âš™ï¸ DÃ©ploiement cloud (AWS EC2, Terraform, Ansible)

### Ã‰tapes dÃ©taillÃ©es
1. **PrÃ©parer les credentials** :
   - Modifier les fichiers sous `srv/_credentials` (clÃ© AWS, clÃ© SSH, etc.).
2. **Adapter les variables** :
   - Modifier les variables dans `srv/deploy_pipeline.sh` et `srv/infra/variables.tf` selon votre environnement (profil AWS, rÃ©gion, type dâ€™instance, etc.).
3. **Lancer le dÃ©ploiement** :
   ```sh
   cd srv
   bash deploy_pipeline.sh
   ```
   - Provisionnement de lâ€™infrastructure (tofu/Terraform)
   - GÃ©nÃ©ration dynamique de lâ€™inventaire Ansible (template Jinja2, script Python commentÃ©)
   - DÃ©ploiement automatisÃ© de tous les services Docker sur les VMs (playbook Ansible commentÃ©)

Chaque Ã©tape, script et configuration est abondamment commentÃ© pour vous guider.

---

## ğŸ”¬ Exemples dâ€™utilisation

### Appel API de prÃ©diction (FastAPI)
```sh
curl -X POST "http://localhost:9999/predict" \
     -H "Content-Type: application/json" \
     -d '{ "feature1": 1.2, "feature2": 0.8, "feature3": 2.1 }'
```
RÃ©ponse attendue :
```json
{
  "prediction": 0,
  "probability": 0.15,
  "status": "success"
}
```

### Utilisation de lâ€™interface Streamlit
- AccÃ©dez Ã  http://localhost:8501
- Remplissez le formulaire, cliquez sur "PrÃ©dire" pour obtenir le rÃ©sultat, visualisez les mÃ©triques et lâ€™historique.

### Gestion des conteneurs
```sh
docker compose logs -f         # Logs en temps rÃ©el
docker compose exec api bash   # AccÃ¨s shell au conteneur API
docker compose exec ui_api_ml bash # AccÃ¨s shell Ã  lâ€™UI ML
```

---

## ğŸ‘¥ Contributeurs

Merci Ã  tous les contributeurs du projetâ€¯:
- [SidyLaye](https://github.com/SidyLaye)
- [adamowski13](https://github.com/adamowski13)
- [Lolowyn](https://github.com/Lolowyn)

Contributions, issues et suggestions sont les bienvenuesâ€¯!

---

## ğŸ“š Ressources utiles
- Documentation FastAPI : https://fastapi.tiangolo.com/
- Documentation Streamlit : https://docs.streamlit.io/
- Documentation Docker Compose : https://docs.docker.com/compose/
- Documentation Terraform : https://www.terraform.io/docs/
- Documentation Ansible : https://docs.ansible.com/

---

## ğŸ“ Licence
Ce projet est distribuÃ© sous licence MIT.
