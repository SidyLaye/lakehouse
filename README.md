<<<<<<< HEAD
<!-- âš ï¸ This README has been generated from the file(s) "blueprint.md" âš ï¸-->
[![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/colored.png)](#lakehouse)
=======
# lakehouse
Pour run le projet sur AWS (Instances Ec2) :

-Pull srv/

-Mordifier les fichier sous srv/_credentials

-modifier les variables dans srv/deploy_pipeline.sh et srv/infra/variables.tf

-Run le script shell

# lakehouse
# Fraud Detection API
>>>>>>> cb5b0ec07bd2b86755c768f132cd95d74bc651aa

# â¤ lakehouse

[![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/colored.png)](#lakehouse)

# â¤ lakehouse

[![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/colored.png)](#fraud-detection-api)

# â¤ Fraud Detection API


[![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/colored.png)](#-dploiement-avec-docker-compose)

## â¤ ğŸ”§ DÃ©ploiement avec Docker Compose

### PrÃ©requis

- Docker et Docker Compose installÃ©s
- Ports 5432, 9999, 9998, 1000, 5000, 9870, 8088, 7077, 8000, 9000, 9001, 9200, 9090, 3000, 9997, 8501 disponibles

### Lancement rapide

```bash
docker compose build
# puis
docker compose up -d
```

### Services disponibles

| Service | URL | Description |
|---------|-----|-------------|
| API Fraud Detection | http://localhost:8000 | API REST de prÃ©diction |
| Documentation API | http://localhost:8000/docs | Interface Swagger automatique |
| Interface Streamlit | http://localhost:8501 | Interface web interactive |

### Test de l'API

#### AccÃ¨s Ã  l'interface Swagger

```
http://localhost:8000/docs
```

#### Test avec fichier JSON

```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d @test_fraud.json
```

#### Exemple de requÃªte de prÃ©diction

```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "feature1": 1.2,
       "feature2": 0.8,
       "feature3": 2.1
     }'
```


[![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/colored.png)](#-interface-streamlit)

## â¤ ğŸ¯ Interface Streamlit

### AccÃ¨s Ã  l'interface web

L'application Streamlit est disponible Ã  l'adresse :

```
http://localhost:8501
```

### FonctionnalitÃ©s

- **Interface intuitive** : Formulaire web pour saisir les donnÃ©es
- **PrÃ©diction temps rÃ©el** : RÃ©sultats instantanÃ©s
- **Visualisations** : Graphiques et mÃ©triques interactives
- **Historique** : Consultation des prÃ©dictions prÃ©cÃ©dentes

### Utilisation

1. Naviguez vers http://localhost:8501
2. Remplissez les champs du formulaire avec les donnÃ©es de transaction
3. Cliquez sur "PrÃ©dire" pour obtenir le rÃ©sultat
4. Consultez la probabilitÃ© de fraude et la classification

### Gestion des containers

#### ArrÃªt des services

```bash
docker compose down
```

#### Consultation des logs

```bash
docker compose logs -f
```

#### Reconstruction aprÃ¨s modification

```bash
docker compose build --no-cache
docker compose up -d
```


[![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/colored.png)](#-utilisation-de-lapi)

## â¤ ğŸ“Š Utilisation de l'API

### Endpoints disponibles

- `POST /predict` - PrÃ©diction de fraude
- `GET /docs` - Documentation Swagger
- `GET /redoc` - Documentation alternative

### Format des donnÃ©es

L'API attend un JSON avec les features du modÃ¨le de dÃ©tection de fraude. Consultez le fichier `test_fraud.json` pour un exemple complet.

### RÃ©ponse de l'API

```json
{
  "prediction": 0,
  "probability": 0.15,
  "status": "success"
}
```


[![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/colored.png)](#-dveloppement)

## â¤ ğŸ› ï¸ DÃ©veloppement

### Structure du projet

```
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ api/                # Backend FastAPI (fraude)
â”œâ”€â”€ sources_api/        # API d'ingestion
â”œâ”€â”€ lakehouse/          # Orchestration, pipeline, MLflow, Spark, MinIO
â”œâ”€â”€ api_ml/             # API ML et UI Streamlit
â”œâ”€â”€ postgres/           # Base de donnÃ©es
â”œâ”€â”€ elasticsearch/      # Moteur de recherche
â”œâ”€â”€ prometheus/         # Monitoring
â”œâ”€â”€ grafana/            # Visualisation
â”œâ”€â”€ srv/                # DÃ©ploiement (Terraform, Ansible)
â””â”€â”€ ...
```

### Logs et debugging

Pour suivre les logs en temps rÃ©el :

```bash
docker compose logs -f
```

### AccÃ¨s aux containers

```bash
# â¤ AccÃ¨s au container API
docker-compose exec fraud-api bash


# â¤ AccÃ¨s au container Streamlit
docker-compose exec streamlit-app bash
```

---

## ğŸ—ï¸ Lakehouse â€” Plateforme de dÃ©tection de fraude, orchestration et analyse de donnÃ©es

Ce projet propose une architecture complÃ¨te de type "lakehouse" pour la dÃ©tection de fraude, l'analyse de donnÃ©es, le monitoring, la visualisation et le dÃ©ploiement automatisÃ©. Il s'appuie sur Docker Compose pour l'orchestration locale, et sur Terraform/Ansible pour le dÃ©ploiement cloud.

---

## ğŸš€ FonctionnalitÃ©s principales
- **API FastAPI** (`api/`) : expose des endpoints REST pour la dÃ©tection de fraude en temps rÃ©el, documentation Swagger intÃ©grÃ©e.
- **API sources** (`sources_api/`) : ingestion, split et gestion des donnÃ©es sources, alimentation de la base PostgreSQL.
- **Pipeline Lakehouse** (`lakehouse/`) : orchestration Spark, MLflow, MinIO, scripts de pipeline, gestion des signaux, datamarts, preprocessing, etc.
- **Machine Learning API** (`api_ml/api/`) : API FastAPI dÃ©diÃ©e Ã  l'infÃ©rence ML.
- **Interface utilisateur ML** (`api_ml/ui/`) : application Streamlit pour la prÃ©diction et la visualisation interactive.
- **Base de donnÃ©es PostgreSQL** (`postgres/`) : stockage relationnel, initialisation automatisÃ©e.
- **Elasticsearch** (`elasticsearch/`) : moteur de recherche et d'indexation.
- **Monitoring Prometheus** (`prometheus/`) : collecte de mÃ©triques, configuration personnalisÃ©e.
- **Visualisation Grafana** (`grafana/`) : dashboards interactifs, provisioning automatisÃ©.
- **DÃ©ploiement automatisÃ©** (`srv/`) : scripts Bash, Terraform, Ansible, gÃ©nÃ©ration dynamique d'inventaire, configuration cloud.

---

## ğŸ“¦ DÃ©marrage rapide (local)

### PrÃ©requis
- Docker et Docker Compose installÃ©s
- Ports suivants disponibles : 5432, 9999, 9998, 1000, 5000, 9870, 8088, 7077, 8000, 9000, 9001, 9200, 9090, 3000, 9997, 8501

### Lancement des services
```bash
docker compose build
# puis
docker compose up -d
```

### ArrÃªt des services
```bash
docker compose down
```

### VÃ©rification
```bash
docker compose ps
```

---

## ğŸ—ºï¸ Architecture des services

| Service         | Port    | Description                                 |
|----------------|---------|---------------------------------------------|
| api            | 9999    | API FastAPI principale (fraude)             |
| sources_api    | 9998    | API d'ingestion de donnÃ©es                  |
| lakehouse      | 1000... | Orchestration, Spark, MLflow, MinIO, etc.   |
| postgres       | 5432    | Base de donnÃ©es relationnelle               |
| elasticsearch  | 9200    | Moteur de recherche                         |
| prometheus     | 9090    | Monitoring                                  |
| grafana        | 3000    | Visualisation                               |
| api_ml         | 9997    | API Machine Learning                        |
| ui_api_ml      | 8501    | Interface utilisateur Streamlit             |

---

## ğŸŒ AccÃ¨s aux interfaces
- **API principale** : http://localhost:9999/docs (Swagger)
- **API sources** : http://localhost:9998/docs
- **Interface ML (Streamlit)** : http://localhost:8501
- **Grafana** : http://localhost:3000
- **Prometheus** : http://localhost:9090

---

## ğŸ”¬ Exemple d'appel API (prÃ©diction)
```bash
curl -X POST "http://localhost:9999/predict" \
     -H "Content-Type: application/json" \
     -d '{ "feature1": 1.2, "feature2": 0.8, "feature3": 2.1 }'
```

RÃ©ponse attendue :
```json
{
  "prediction": 0,
  "probability": 0.15,
  "status": "success"
}
```

---

## ğŸ› ï¸ Structure dÃ©taillÃ©e du projet

```
.
â”œâ”€â”€ docker-compose.yml         # Orchestration multi-conteneurs (commentÃ©)
â”œâ”€â”€ api/                      # Backend FastAPI (routes, schÃ©mas, BDD, features)
â”‚   â”œâ”€â”€ fastapi_app.py        # Application principale FastAPI
â”‚   â”œâ”€â”€ database.py           # Connexion et gestion PostgreSQL
â”‚   â”œâ”€â”€ schemas.py            # ModÃ¨les Pydantic
â”‚   â”œâ”€â”€ routers/              # Routes modulaires (features, risques, etc.)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ sources_api/              # API d'ingestion, split, alimentation BDD
â”‚   â”œâ”€â”€ api.py                # FastAPI pour ingestion
â”‚   â”œâ”€â”€ db.py                 # Chargement CSV â†’ PostgreSQL
â”‚   â”œâ”€â”€ split.py              # DÃ©coupe de CSV (script commentÃ©)
â”‚   â”œâ”€â”€ requirements.txt      # DÃ©pendances commentÃ©es
â”‚   â””â”€â”€ ...
â”œâ”€â”€ lakehouse/                # Orchestration, pipeline, MLflow, Spark, MinIO
â”‚   â”œâ”€â”€ orchestrator.py       # Orchestration globale (commentÃ©)
â”‚   â”œâ”€â”€ mlflow_minio_artifact_repo.py # IntÃ©gration MLflow/MinIO
â”‚   â”œâ”€â”€ entrypoint.sh         # Script d'entrÃ©e (commentÃ©)
â”‚   â”œâ”€â”€ pipeline/             # Scripts pipeline (datamarts, feeder, ml, etc.)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ api_ml/                   # API ML et UI Streamlit
â”‚   â”œâ”€â”€ api/main.py           # API FastAPI ML (commentÃ©)
â”‚   â”œâ”€â”€ ui/streamlit_app.py   # Interface Streamlit (commentÃ©e)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ postgres/                 # Base de donnÃ©es PostgreSQL (Dockerfile, init.sql commentÃ©s)
â”œâ”€â”€ elasticsearch/            # Dockerfile commentÃ©
â”œâ”€â”€ prometheus/               # Dockerfile, prometheus.yml commentÃ©s
â”œâ”€â”€ grafana/                  # Dockerfile commentÃ©
â”œâ”€â”€ srv/                      # DÃ©ploiement cloud (scripts, Ansible, Terraform)
â”‚   â”œâ”€â”€ deploy_pipeline.sh    # Script Bash commentÃ©
â”‚   â”œâ”€â”€ ansible/              # Playbook, inventaire, templates commentÃ©s
â”‚   â”œâ”€â”€ infra/                # main.tf, variables.tf commentÃ©s
â”‚   â””â”€â”€ ...
â”œâ”€â”€ .lfsconfig                # Config LFS (commentÃ©e)
â””â”€â”€ README.md                 # Ce fichier
```

---

## âš™ï¸ DÃ©ploiement cloud (optionnel)

Pour dÃ©ployer sur AWS EC2 avec Terraform et Ansible (scripts commentÃ©s) :

```bash
cd srv
bash deploy_pipeline.sh
```

- Provisionnement de l'infra (tofu/Terraform)
- GÃ©nÃ©ration dynamique de l'inventaire Ansible (template Jinja2)
- DÃ©ploiement automatisÃ© de tous les services Docker sur les VMs

---

## ğŸ“ DÃ©tail des fichiers de configuration et scripts

- **docker-compose.yml** : chaque service, port, dÃ©pendance et rÃ©seau est commentÃ© pour expliquer son rÃ´le.
- **requirements.txt** (sources_api/) : chaque dÃ©pendance est expliquÃ©e ligne par ligne.
- **split.py** (sources_api/) : script de dÃ©coupe CSV, chaque section est commentÃ©e.
- **entrypoint.sh** (sources_api/, lakehouse/) : scripts d'entrÃ©e, commentaires sur chaque Ã©tape (attente BDD, alimentation, exÃ©cution).
- **orchestrator.py, mlflow_minio_artifact_repo.py** (lakehouse/) : orchestration, gestion artefacts, commentaires dÃ©taillÃ©s.
- **pipeline/** (lakehouse/) : chaque script (datamarts, feeder, ml, preprocessing, signals) est commentÃ© pour expliquer la logique mÃ©tier.
- **Dockerfile** (tous dossiers) : chaque Ã©tape d'installation, configuration, lancement de service est expliquÃ©e.
- **prometheus.yml** : chaque section de configuration et cible de monitoring est commentÃ©e.
- **init.sql** (postgres/) : script d'initialisation de la base, commentaires sur chaque commande SQL.
- **ansible/** (srv/) : playbook, inventaire, templates et scripts Python sont commentÃ©s pour expliquer le dÃ©ploiement automatisÃ©.
- **main.tf, variables.tf** (srv/infra/) : chaque ressource et variable Terraform est expliquÃ©e.
- **.lfsconfig** : configuration LFS, commentaire sur l'usage.

---

## ğŸ“š Ressources utiles
- Documentation FastAPI : https://fastapi.tiangolo.com/
- Documentation Streamlit : https://docs.streamlit.io/
- Documentation Docker Compose : https://docs.docker.com/compose/
- Documentation Terraform : https://www.terraform.io/docs/
- Documentation Ansible : https://docs.ansible.com/

---

## ğŸ‘¤ Auteurs & contact
- Sidy Laye (https://gitlab.com/SidyLaye)
- Contributions bienvenues !

---

## ğŸ“ Licence
Ce projet est distribuÃ© sous licence MIT.
